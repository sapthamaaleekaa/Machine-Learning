{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from pandasql import sqldf\n",
    "pysqldf = lambda q: sqldf(q, globals())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.getcwd()\n",
    "os.chdir(\"C:\\\\Users\\\\Home\\\\Desktop\\\\Saptha\\\\Machine-Learning\\\\WNS\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For cluster computing using ipyparallel.\n",
    "import ipyparallel as ipp\n",
    "rc = ipp.Client()\n",
    "ar = rc[:].apply_async(os.getpid)\n",
    "pid_map = ar.get_dict()\n",
    "print (rc[:].apply_sync(lambda : \"Hello, World\"))\n",
    "\n",
    "# Invoke garbage collector in python\n",
    "import gc "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Datasets\n",
    "\n",
    "trainAnalysis = pd.read_csv('train.csv')\n",
    "itemDataAnalysis = pd.read_csv('item_data.csv')\n",
    "viewLogAnalysis = pd.read_csv('view_log.csv')\n",
    "test = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split dateTime as date and time seperately!!\n",
    "trainAnalysis['impression_date'] = trainAnalysis.impression_time.str.split().str[0]\n",
    "trainAnalysis['impression_timeStamp'] = trainAnalysis.impression_time.str.split().str[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>impression_id</th>\n",
       "      <th>impression_time</th>\n",
       "      <th>user_id</th>\n",
       "      <th>app_code</th>\n",
       "      <th>os_version</th>\n",
       "      <th>is_4G</th>\n",
       "      <th>is_click</th>\n",
       "      <th>impression_date</th>\n",
       "      <th>impression_timeStamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>c4ca4238a0b923820dcc509a6f75849b</td>\n",
       "      <td>2018-11-15 00:00:00</td>\n",
       "      <td>87862</td>\n",
       "      <td>422</td>\n",
       "      <td>old</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2018-11-15</td>\n",
       "      <td>00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>45c48cce2e2d7fbdea1afc51c7c6ad26</td>\n",
       "      <td>2018-11-15 00:01:00</td>\n",
       "      <td>63410</td>\n",
       "      <td>467</td>\n",
       "      <td>latest</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2018-11-15</td>\n",
       "      <td>00:01:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>70efdf2ec9b086079795c442636b55fb</td>\n",
       "      <td>2018-11-15 00:02:00</td>\n",
       "      <td>71748</td>\n",
       "      <td>259</td>\n",
       "      <td>intermediate</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2018-11-15</td>\n",
       "      <td>00:02:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8e296a067a37563370ded05f5a3bf3ec</td>\n",
       "      <td>2018-11-15 00:02:00</td>\n",
       "      <td>69209</td>\n",
       "      <td>244</td>\n",
       "      <td>latest</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2018-11-15</td>\n",
       "      <td>00:02:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>182be0c5cdcd5072bb1864cdee4d3d6e</td>\n",
       "      <td>2018-11-15 00:02:00</td>\n",
       "      <td>62873</td>\n",
       "      <td>473</td>\n",
       "      <td>latest</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2018-11-15</td>\n",
       "      <td>00:02:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      impression_id      impression_time  user_id  app_code  \\\n",
       "0  c4ca4238a0b923820dcc509a6f75849b  2018-11-15 00:00:00    87862       422   \n",
       "1  45c48cce2e2d7fbdea1afc51c7c6ad26  2018-11-15 00:01:00    63410       467   \n",
       "2  70efdf2ec9b086079795c442636b55fb  2018-11-15 00:02:00    71748       259   \n",
       "3  8e296a067a37563370ded05f5a3bf3ec  2018-11-15 00:02:00    69209       244   \n",
       "4  182be0c5cdcd5072bb1864cdee4d3d6e  2018-11-15 00:02:00    62873       473   \n",
       "\n",
       "     os_version  is_4G  is_click impression_date impression_timeStamp  \n",
       "0           old      0         0      2018-11-15             00:00:00  \n",
       "1        latest      1         1      2018-11-15             00:01:00  \n",
       "2  intermediate      1         0      2018-11-15             00:02:00  \n",
       "3        latest      1         0      2018-11-15             00:02:00  \n",
       "4        latest      0         0      2018-11-15             00:02:00  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Exploratory Data Analysis\n",
    "trainAnalysis.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainAnalysisSorted = pysqldf(\"SELECT * FROM trainAnalysis order by user_id ASC, impression_date ASC, impression_timeStamp ASC;\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainAnalysisSorted['impressionCountPerUserPerDay'] = pysqldf(\"SELECT count(*) over (partition by user_id, impression_date) AS impression_count_per_day from trainAnalysisSorted t;\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainAnalysisSorted['impressionCountPerUserPerDayPerApp'] = pysqldf(\"SELECT count(*) over (partition by user_id, impression_date, app_code) AS impressionCountPerUserPerDayPerApp from trainAnalysisSorted t;\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainAnalysisSorted['impressionCountPerUserPerApp'] = pysqldf(\"SELECT count(*) over (partition by user_id, app_code) AS impressionCountPerUserPerApp from trainAnalysisSorted t;\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(237609, 12)\n",
      "237609\n"
     ]
    }
   ],
   "source": [
    "print (trainAnalysisSorted.shape)\n",
    "# (237609, 12)\n",
    "print (trainAnalysisSorted.impression_id.nunique(dropna = True))\n",
    "# 237609\n",
    "# So each impression is unique, i.e. impression has nothing to do with item_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "latest          129216\n",
      "intermediate     55543\n",
      "old              52850\n",
      "Name: os_version, dtype: int64\n",
      "3    129216\n",
      "2     55543\n",
      "1     52850\n",
      "Name: os_version, dtype: int64\n"
     ]
    }
   ],
   "source": [
    " # Lets encode os_version with label encoder as it is ordinally categorical.\n",
    "print (trainAnalysisSorted['os_version'].value_counts())\n",
    "trainAnalysisSorted.replace({'os_version':{'old':'1','intermediate':'2','latest':'3'}}, inplace=True)\n",
    "print (trainAnalysisSorted['os_version'].value_counts())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    226747\n",
      "1     10862\n",
      "Name: is_click, dtype: int64\n",
      "0    49678\n",
      "1     2181\n",
      "Name: is_click, dtype: int64\n",
      "0    123834\n",
      "1      5382\n",
      "Name: is_click, dtype: int64\n",
      "0    82009\n",
      "1     3842\n",
      "Name: is_click, dtype: int64\n",
      "0    18169\n",
      "1      952\n",
      "Name: is_click, dtype: int64\n",
      "0    52668\n",
      "1     2875\n",
      "Name: is_click, dtype: int64\n",
      "0    36083\n",
      "1     1896\n",
      "Name: is_click, dtype: int64\n",
      "0    14162\n",
      "1      709\n",
      "Name: is_click, dtype: int64\n",
      "0    50245\n",
      "1     2605\n",
      "Name: is_click, dtype: int64\n",
      "0    144738\n",
      "1      7020\n",
      "Name: is_click, dtype: int64\n",
      "0    74156\n",
      "1     3201\n",
      "Name: is_click, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print (trainAnalysisSorted.is_click.value_counts())\n",
    "# 0    226747\n",
    "# 1     10862\n",
    "# % of 0's : 95.42%\n",
    "# % of 1's : 4.57%\n",
    "\n",
    "print (pysqldf(\"SELECT * from trainAnalysisSorted where os_version = 3 and is_4G = 1;\").is_click.value_counts())\n",
    "# 0    49678\n",
    "# 1     2181\n",
    "# % of 0's : 95.79%\n",
    "# % of 1's : 4.26%\n",
    "\n",
    "print (pysqldf(\"SELECT * from trainAnalysisSorted where os_version = 3;\").is_click.value_counts())\n",
    "# 0    123834\n",
    "# 1      5382\n",
    "# % of 0's : 95.83%\n",
    "# % of 1's : 4.16%\n",
    "\n",
    "print (pysqldf(\"SELECT * from trainAnalysisSorted where is_4G = 1;\").is_click.value_counts())\n",
    "# 0    82009\n",
    "# 1     3842\n",
    "# % of 0's : 95.52%\n",
    "# % of 1's : 4.47%\n",
    "\n",
    "print (pysqldf(\"SELECT * from trainAnalysisSorted where os_version = 2 and is_4G = 1;\").is_click.value_counts())\n",
    "# 0    18169\n",
    "# 1      952\n",
    "# % of 0's : 95.02%\n",
    "# % of 1's : 4.97%\n",
    "\n",
    "print (pysqldf(\"SELECT * from trainAnalysisSorted where os_version = 2;\").is_click.value_counts())\n",
    "# 0    52668\n",
    "# 1     2875\n",
    "# % of 0's : 94.82%\n",
    "# % of 1's : 5.17%\n",
    "\n",
    "print (pysqldf(\"SELECT * from trainAnalysisSorted where os_version = 1 and is_4G = 0;\").is_click.value_counts())\n",
    "# 0    36083\n",
    "# 1    1896\n",
    "# % of 0's : 95%\n",
    "# % of 1's : 4.99%\n",
    "\n",
    "print (pysqldf(\"SELECT * from trainAnalysisSorted where os_version = 1 and is_4G = 1;\").is_click.value_counts())\n",
    "# 0    14162\n",
    "# 1      709\n",
    "# % of 0's : 95.23%\n",
    "# % of 1's : 4.76%\n",
    "\n",
    "print (pysqldf(\"SELECT * from trainAnalysisSorted where os_version = 1;\").is_click.value_counts())\n",
    "# 0    50245\n",
    "# 1     2605\n",
    "# % of 0's : 95%\n",
    "# % of 1's : 4.92%\n",
    "\n",
    "print (pysqldf(\"SELECT * from trainAnalysisSorted where is_4G = 0;\").is_click.value_counts())\n",
    "# 0    144738\n",
    "# 1      7020\n",
    "# % of 0's : 95.37%\n",
    "# % of 1's : 4.62%\n",
    "\n",
    "print (pysqldf(\"SELECT * from trainAnalysisSorted where os_version = 3 and is_4G = 0;\").is_click.value_counts())\n",
    "# 0    74156\n",
    "# 1     3201\n",
    "# % of 0's : 95.86%\n",
    "# % of 1's : 4.13%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3118622, 5)\n",
      "(132761, 6)\n",
      "74723\n",
      "89157\n",
      "(237609, 12)\n",
      "0    226747\n",
      "1     10862\n",
      "Name: is_click, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print (viewLogAnalysis.shape)\n",
    "print (itemDataAnalysis.shape)\n",
    "print (trainAnalysisSorted.user_id.nunique(dropna = True))\n",
    "print (viewLogAnalysis.user_id.nunique(dropna = True))\n",
    "print (trainAnalysisSorted.shape)\n",
    "print (trainAnalysisSorted.is_click.value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pysqldf(\"select * from viewLogAnalysis where item_id not in (select item_id from itemDataAnalysis);\").shape\n",
    "# (1782, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pysqldf(\"select * from viewLogAnalysis where item_id is NULL;\").shape\n",
    "# (0, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3118622, 10)\n",
      "(3118622, 5)\n",
      "126708\n",
      "132761\n",
      "126708\n",
      "Index(['server_time', 'device_type', 'session_id', 'user_id', 'item_id',\n",
      "       'item_price', 'category_1', 'category_2', 'category_3', 'product_type'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Using Left Join because, Some items in view log table are not present in item log table.\n",
    "ViewLgItmDatDf = pysqldf(\"SELECT V.server_time, V.device_type, V.session_id, V.user_id, V.item_id, I.item_price, I.category_1, I.category_2, I.category_3, I.product_type from viewLogAnalysis V LEFT JOIN itemDataAnalysis I ON V.item_id = I.item_id;\")\n",
    "\n",
    "print (ViewLgItmDatDf.shape)\n",
    "print (viewLogAnalysis.shape)\n",
    "print (viewLogAnalysis.item_id.nunique())\n",
    "print (itemDataAnalysis.item_id.nunique())\n",
    "print (ViewLgItmDatDf.item_id.nunique())\n",
    "print (ViewLgItmDatDf.columns)\n",
    "\n",
    "del viewLogAnalysis\n",
    "del itemDataAnalysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "216"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Enabling garbage collection\n",
    "gc.collect() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export the data for analysis using Excel !\n",
    "# ViewLgItmDatDf.to_csv('ViewLgItmDatDf.csv') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>server_time</th>\n",
       "      <th>device_type</th>\n",
       "      <th>session_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>item_price</th>\n",
       "      <th>category_1</th>\n",
       "      <th>category_2</th>\n",
       "      <th>category_3</th>\n",
       "      <th>product_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3118617</th>\n",
       "      <td>2018-12-11 23:59:00</td>\n",
       "      <td>android</td>\n",
       "      <td>135534</td>\n",
       "      <td>49480</td>\n",
       "      <td>1013</td>\n",
       "      <td>41472.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>115.0</td>\n",
       "      <td>9461.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3118618</th>\n",
       "      <td>2018-12-11 23:59:00</td>\n",
       "      <td>android</td>\n",
       "      <td>206169</td>\n",
       "      <td>70215</td>\n",
       "      <td>44826</td>\n",
       "      <td>2073.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>287.0</td>\n",
       "      <td>5568.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3118619</th>\n",
       "      <td>2018-12-11 23:59:00</td>\n",
       "      <td>android</td>\n",
       "      <td>831039</td>\n",
       "      <td>4925</td>\n",
       "      <td>86608</td>\n",
       "      <td>320.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>9362.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3118620</th>\n",
       "      <td>2018-12-11 23:59:00</td>\n",
       "      <td>android</td>\n",
       "      <td>601193</td>\n",
       "      <td>16870</td>\n",
       "      <td>38284</td>\n",
       "      <td>2176.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>223.0</td>\n",
       "      <td>10083.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3118621</th>\n",
       "      <td>2018-12-11 23:59:00</td>\n",
       "      <td>android</td>\n",
       "      <td>138217</td>\n",
       "      <td>1007</td>\n",
       "      <td>88331</td>\n",
       "      <td>1843.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1761.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 server_time device_type  session_id  user_id  item_id  \\\n",
       "3118617  2018-12-11 23:59:00     android      135534    49480     1013   \n",
       "3118618  2018-12-11 23:59:00     android      206169    70215    44826   \n",
       "3118619  2018-12-11 23:59:00     android      831039     4925    86608   \n",
       "3118620  2018-12-11 23:59:00     android      601193    16870    38284   \n",
       "3118621  2018-12-11 23:59:00     android      138217     1007    88331   \n",
       "\n",
       "         item_price  category_1  category_2  category_3  product_type  \n",
       "3118617     41472.0         1.0        42.0       115.0        9461.0  \n",
       "3118618      2073.0        13.0        78.0       287.0        5568.0  \n",
       "3118619       320.0         4.0         1.0       111.0        9362.0  \n",
       "3118620      2176.0        10.0        43.0       223.0       10083.0  \n",
       "3118621      1843.0        11.0        51.0        14.0        1761.0  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ViewLgItmDatDf.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pysqldf(\"select * from ViewLgItmDatDf where item_price is NULL;\").shape\n",
    "# (1782, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pysqldf(\"SELECT * from ViewLgItmDatDf group by user_id,item_id;\").head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pysqldf(\"SELECT * from trainAnalysisSorted order by user_id;\").head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "isClickUserId = pysqldf(\"SELECT DISTINCT user_id from trainAnalysisSorted where is_click = 1;\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3118622 entries, 0 to 3118621\n",
      "Data columns (total 14 columns):\n",
      "server_time          object\n",
      "device_type          object\n",
      "session_id           int64\n",
      "user_id              int64\n",
      "item_id              int64\n",
      "item_price           float64\n",
      "category_1           float64\n",
      "category_2           float64\n",
      "category_3           float64\n",
      "product_type         float64\n",
      "server_date          object\n",
      "server_timeStamp     object\n",
      "previousDateFinal    object\n",
      "gapInVisit           timedelta64[ns]\n",
      "dtypes: float64(5), int64(3), object(5), timedelta64[ns](1)\n",
      "memory usage: 333.1+ MB\n"
     ]
    }
   ],
   "source": [
    "# Split dateTime as date and time seperately!!\n",
    "ViewLgItmDatDf['server_date'] = ViewLgItmDatDf.server_time.str.split().str[0]\n",
    "ViewLgItmDatDf['server_timeStamp'] = ViewLgItmDatDf.server_time.str.split().str[1]\n",
    "\n",
    "# Sort based on user_id!!\n",
    "ViewLgItmDatDfSorted = pysqldf(\"SELECT * from ViewLgItmDatDf order by user_id,server_time;\")\n",
    "\n",
    "# Extracting the gap in visiting Zbay website.\n",
    "ViewLgItmDatDfSorted['previousDate'] = pysqldf(\"SELECT lag(server_date,1) over (partition by user_id order by server_date) from ViewLgItmDatDfSorted;\")\n",
    "ViewLgItmDatDfSorted['previousDateFinal'] = pysqldf(\"select CASE WHEN previousDate is NULL THEN server_date ELSE previousDate END as previousDateFinal FROM ViewLgItmDatDfSorted;\")\n",
    "del ViewLgItmDatDfSorted['previousDate']\n",
    "ViewLgItmDatDfSorted['gapInVisit'] = pd.to_datetime(ViewLgItmDatDfSorted['server_date'], format='%Y-%m-%d') - pd.to_datetime(ViewLgItmDatDfSorted['previousDateFinal'], format='%Y-%m-%d')\n",
    "ViewLgItmDatDfSorted.info()\n",
    "ViewLgItmDatDfSorted['gapInVisit'] = ViewLgItmDatDfSorted['gapInVisit'].dt.days.astype('int16')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyzing user pattern of visiting the website, for users who clicked the ad. atleast once versus users who never clicked.\n",
    "# clickedAtleastOnceUserPattern = pysqldf(\"SELECT * from ViewLgItmDatDfSorted where user_id IN (SELECT DISTINCT user_id from trainAnalysisSorted where is_click = 1);\")\n",
    "# notEvenOnceClickedUserPattern = pysqldf(\"SELECT * from ViewLgItmDatDfSorted where user_id NOT IN (SELECT DISTINCT user_id from trainAnalysisSorted where is_click = 1);\")\n",
    "\n",
    "# Export the data for analysis using Excel !\n",
    "# clickedAtleastOnceUserPattern.to_csv('clickedAtleastOnceUserPattern.csv') \n",
    "# notEvenOnceClickedUserPattern.to_csv('notEvenOnceClickedUserPattern.csv') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "ViewLgItmDatDfSorted['noOfLogs'] = pysqldf(\"select count(*) over (partition by user_id order by server_time) from ViewLgItmDatDfSorted;\")\n",
    "log = pysqldf(\"select user_id, server_time, noOfLogs from ViewLgItmDatDfSorted;\")\n",
    "trainAnalysisSorted['NoOfLgsBfThtDay'] = pysqldf(\"select max(noOfLogs) from trainAnalysisSorted inner join log where trainAnalysisSorted.user_id = log.user_id and ((trainAnalysisSorted.impression_time > log.server_time) or (trainAnalysisSorted.impression_time = log.server_time))  group by trainAnalysisSorted.user_id,trainAnalysisSorted.impression_time;\")\n",
    "del log\n",
    "#trainAnalysisSorted['NoOfLgsBfThtDay'].isna().sum()\n",
    "trainAnalysisSorted['NoOfLgsBfThtDay'].fillna(0,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ViewLgItmDatDfSorted['device_type'].value_counts()\n",
    "device = pysqldf(\"select user_id, device_type, count(*) from ViewLgItmDatDfSorted group by user_id,device_type;\")\n",
    "trainAnalysisSorted['device_type'] = pysqldf(\"select d.device_type from trainAnalysisSorted t inner join device d where t.user_id = d.user_id;\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# device_type is not ordinal data, so lets dummy encode it.\n",
    "trainAnalysisSorted = pd.get_dummies(trainAnalysisSorted, columns=['device_type'], prefix = ['device'])\n",
    "del device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1340800.0\n",
      "5.0\n",
      "(1000, 5000]          1458012\n",
      "(5000, 10000]          416693\n",
      "(10000, 25000]         398256\n",
      "(500, 1000]            355306\n",
      "(0, 500]               190783\n",
      "(25000, 50000]         147193\n",
      "(50000, 100000]        100404\n",
      "(100000, 150000]        26943\n",
      "(150000, 200000]        16339\n",
      "(200000, 250000]         4588\n",
      "(250000, 500000]         2104\n",
      "(500000, 750000]          192\n",
      "(750000, 1000000]          26\n",
      "(1250000, 1500000]          1\n",
      "(1000000, 1250000]          0\n",
      "Name: item_price, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Determining how to choose bins for price tags!!!\n",
    "print (np.max(ViewLgItmDatDfSorted['item_price']))\n",
    "print (np.min(ViewLgItmDatDfSorted['item_price']))\n",
    "print (pd.cut(ViewLgItmDatDfSorted['item_price'], [0,500,1000,5000,10000,25000,50000,100000,150000,200000,250000,500000,750000,1000000,1250000,1500000]).value_counts())\n",
    "ViewLgItmDatDfSorted['item_price_bins'] = pd.cut(ViewLgItmDatDfSorted['item_price'], [0,500,1000,5000,10000,25000,50000,100000,150000,200000,250000,500000,750000,1000000,1250000,1500000],labels=[\"[0, 500]\", \"[500, 1000]\", \"[1000, 5000]\", \"[5000, 10000]\", \"[10000, 25000]\",\"[25000, 50000]\",\"[50000, 100000]\",\"[100000,150000]\",\"[150000,200000]\",\"[200000,250000]\",\"[250000,500000]\",\"[500000, 750000]\", \"[750000, 1000000]\", \"[1000000, 1250000]\", \"[1250000, 1500000]\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "339"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Enabling garbage collection\n",
    "gc.collect() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Determining how to choose bins for price tags!!!\n",
    "print (np.max(ViewLgItmDatDfSorted['item_price']))\n",
    "print (np.min(ViewLgItmDatDfSorted['item_price']))\n",
    "print (pd.cut(ViewLgItmDatDfSorted['item_price'], [0,500,1000,5000,10000,25000,50000,100000,150000,200000,250000,500000,750000,1000000,1250000,1500000]).value_counts())\n",
    "ViewLgItmDatDfSorted['item_price_bins'] = pd.cut(ViewLgItmDatDfSorted['item_price'], [0,500,1000,5000,10000,25000,50000,100000,150000,200000,250000,500000,750000,1000000,1250000,1500000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ****** Executed ****** \n",
      " ****** Executed ****** \n",
      " ****** Executed ****** \n",
      " ****** Executed ****** \n",
      " ****** Executed ****** \n",
      " ****** Executed ****** \n",
      " ****** Executed ****** \n",
      " ****** Executed ****** \n",
      " ****** Executed ****** \n",
      " ****** Executed ****** \n",
      " ****** Executed ****** \n",
      " ****** Executed ****** \n",
      " ****** Executed ****** \n",
      " ****** Executed ****** \n",
      " ****** Executed ****** \n"
     ]
    }
   ],
   "source": [
    "ViewLgItmDatDfSorted['_0_500_YN'] = 0\n",
    "ViewLgItmDatDfSorted.loc[ViewLgItmDatDfSorted.item_price_bins == '[0, 500]', '_0_500_YN'] = 1 \n",
    "ViewLgItmDatDfSorted['_0_500_count'] = pysqldf(\"SELECT SUM(_0_500_YN) over (PARTITION BY user_id order by server_time) from ViewLgItmDatDfSorted;\")\n",
    "del ViewLgItmDatDfSorted['_0_500_YN'] \n",
    "gc.collect() \n",
    "print (\" ****** Executed ****** \")\n",
    "\n",
    "ViewLgItmDatDfSorted['_500_1000_YN'] = 0\n",
    "ViewLgItmDatDfSorted.loc[ViewLgItmDatDfSorted.item_price_bins == '[500, 1000]', '_500_1000_YN'] = 1 \n",
    "ViewLgItmDatDfSorted['_500_1000_count'] = pysqldf(\"SELECT SUM(_500_1000_YN) over (PARTITION BY user_id order by server_time) from ViewLgItmDatDfSorted;\")\n",
    "del ViewLgItmDatDfSorted['_500_1000_YN'] \n",
    "gc.collect() \n",
    "print (\" ****** Executed ****** \")\n",
    "\n",
    "ViewLgItmDatDfSorted['_1000_5000_YN'] = 0\n",
    "ViewLgItmDatDfSorted.loc[ViewLgItmDatDfSorted.item_price_bins == '[1000, 5000]', '_1000_5000_YN'] = 1  \n",
    "ViewLgItmDatDfSorted['_1000_5000_count'] = pysqldf(\"SELECT SUM(_1000_5000_YN) over (PARTITION BY user_id order by server_time) from ViewLgItmDatDfSorted;\")\n",
    "del ViewLgItmDatDfSorted['_1000_5000_YN'] \n",
    "gc.collect() \n",
    "print (\" ****** Executed ****** \")\n",
    "\n",
    "ViewLgItmDatDfSorted['_5000_10000_YN'] = 0\n",
    "ViewLgItmDatDfSorted.loc[ViewLgItmDatDfSorted.item_price_bins == '[5000, 10000]', '_5000_10000_YN'] = 1 \n",
    "ViewLgItmDatDfSorted['_5000_10000_count'] = pysqldf(\"SELECT SUM(_5000_10000_YN) over (PARTITION BY user_id order by server_time) from ViewLgItmDatDfSorted;\")\n",
    "del ViewLgItmDatDfSorted['_5000_10000_YN'] \n",
    "gc.collect() \n",
    "print (\" ****** Executed ****** \")\n",
    "\n",
    "ViewLgItmDatDfSorted['_10000_25000_YN'] = 0\n",
    "ViewLgItmDatDfSorted.loc[ViewLgItmDatDfSorted.item_price_bins == '[10000, 25000]', '_10000_25000_YN'] = 1 \n",
    "ViewLgItmDatDfSorted['_10000_25000_count'] = pysqldf(\"SELECT SUM(_10000_25000_YN) over (PARTITION BY user_id order by server_time) from ViewLgItmDatDfSorted;\")\n",
    "del ViewLgItmDatDfSorted['_10000_25000_YN'] \n",
    "gc.collect() \n",
    "print (\" ****** Executed ****** \")\n",
    "\n",
    "ViewLgItmDatDfSorted['_25000_50000_YN'] = 0\n",
    "ViewLgItmDatDfSorted.loc[ViewLgItmDatDfSorted.item_price_bins == '[25000, 50000]', '_25000_50000_YN'] = 1  \n",
    "ViewLgItmDatDfSorted['_25000_50000_count'] = pysqldf(\"SELECT SUM(_25000_50000_YN) over (PARTITION BY user_id order by server_time) from ViewLgItmDatDfSorted;\")\n",
    "del ViewLgItmDatDfSorted['_25000_50000_YN'] \n",
    "gc.collect() \n",
    "print (\" ****** Executed ****** \")\n",
    "\n",
    "ViewLgItmDatDfSorted['_50000_100000_YN'] = 0\n",
    "ViewLgItmDatDfSorted.loc[ViewLgItmDatDfSorted.item_price_bins == '[50000, 100000]', '_50000_100000_YN'] = 1  \n",
    "ViewLgItmDatDfSorted['_50000_100000_count'] = pysqldf(\"SELECT SUM(_50000_100000_YN) over (PARTITION BY user_id order by server_time) from ViewLgItmDatDfSorted;\")\n",
    "del ViewLgItmDatDfSorted['_50000_100000_YN'] \n",
    "gc.collect() \n",
    "print (\" ****** Executed ****** \")\n",
    "\n",
    "ViewLgItmDatDfSorted['_100000_150000_YN'] = 0\n",
    "ViewLgItmDatDfSorted.loc[ViewLgItmDatDfSorted.item_price_bins == '[100000,150000]', '_100000_150000_YN'] = 1  \n",
    "ViewLgItmDatDfSorted['_100000_150000_count'] = pysqldf(\"SELECT SUM(_100000_150000_YN) over (PARTITION BY user_id order by server_time) from ViewLgItmDatDfSorted;\")\n",
    "del ViewLgItmDatDfSorted['_100000_150000_YN'] \n",
    "print (\" ****** Executed ****** \")\n",
    " \n",
    "ViewLgItmDatDfSorted['_150000_200000_YN'] = 0\n",
    "ViewLgItmDatDfSorted.loc[ViewLgItmDatDfSorted.item_price_bins == '[150000,200000]', '_150000_200000_YN'] = 1  \n",
    "ViewLgItmDatDfSorted['_150000_200000_count'] = pysqldf(\"SELECT SUM(_150000_200000_YN) over (PARTITION BY user_id order by server_time) from ViewLgItmDatDfSorted;\")\n",
    "del ViewLgItmDatDfSorted['_150000_200000_YN'] \n",
    "gc.collect() \n",
    "print (\" ****** Executed ****** \")\n",
    "\n",
    "ViewLgItmDatDfSorted['_200000_250000_YN'] = 0\n",
    "ViewLgItmDatDfSorted.loc[ViewLgItmDatDfSorted.item_price_bins == '[200000,250000]', '_200000_250000_YN'] = 1  \n",
    "ViewLgItmDatDfSorted['_200000_250000_count'] = pysqldf(\"SELECT SUM(_200000_250000_YN) over (PARTITION BY user_id order by server_time) from ViewLgItmDatDfSorted;\")\n",
    "del ViewLgItmDatDfSorted['_200000_250000_YN'] \n",
    "gc.collect() \n",
    "print (\" ****** Executed ****** \")\n",
    "\n",
    "ViewLgItmDatDfSorted['_250000_500000_YN'] = 0\n",
    "ViewLgItmDatDfSorted.loc[ViewLgItmDatDfSorted.item_price_bins == '[250000,500000]', '_250000_500000_YN'] = 1  \n",
    "ViewLgItmDatDfSorted['_250000_500000_count'] = pysqldf(\"SELECT SUM(_250000_500000_YN) over (PARTITION BY user_id order by server_time) from ViewLgItmDatDfSorted;\")\n",
    "del ViewLgItmDatDfSorted['_250000_500000_YN'] \n",
    "gc.collect() \n",
    "print (\" ****** Executed ****** \")\n",
    "\n",
    "ViewLgItmDatDfSorted['_500000_750000_YN'] = 0\n",
    "ViewLgItmDatDfSorted.loc[ViewLgItmDatDfSorted.item_price_bins == '[500000, 750000]', '_500000_750000_YN'] = 1\n",
    "ViewLgItmDatDfSorted['_500000_750000_count'] = pysqldf(\"SELECT SUM(_500000_750000_YN) over (PARTITION BY user_id order by server_time) from ViewLgItmDatDfSorted;\")\n",
    "del ViewLgItmDatDfSorted['_500000_750000_YN']\n",
    "gc.collect() \n",
    "print (\" ****** Executed ****** \")\n",
    "\n",
    "ViewLgItmDatDfSorted['_750000_1000000_YN'] = 0\n",
    "ViewLgItmDatDfSorted.loc[ViewLgItmDatDfSorted.item_price_bins == '[750000, 1000000]', '_750000_1000000_YN'] = 1 \n",
    "ViewLgItmDatDfSorted['_750000_1000000_count'] = pysqldf(\"SELECT SUM(_750000_1000000_YN) over (PARTITION BY user_id order by server_time) from ViewLgItmDatDfSorted;\")\n",
    "del ViewLgItmDatDfSorted['_750000_1000000_YN'] \n",
    "gc.collect() \n",
    "print (\" ****** Executed ****** \")\n",
    "\n",
    "ViewLgItmDatDfSorted['_1000000_1250000_YN'] = 0\n",
    "\n",
    "\n",
    "ViewLgItmDatDfSorted.loc[ViewLgItmDatDfSorted.item_price_bins == '[1000000, 1250000]', '_1000000_1250000_YN'] = 1 \n",
    "ViewLgItmDatDfSorted['_1000000_1250000_count'] = pysqldf(\"SELECT SUM(_1000000_1250000_YN) over (PARTITION BY user_id order by server_time) from ViewLgItmDatDfSorted;\")\n",
    "del ViewLgItmDatDfSorted['_1000000_1250000_YN']\n",
    "gc.collect() \n",
    "print (\" ****** Executed ****** \")\n",
    "\n",
    "ViewLgItmDatDfSorted['_1250000_1500000_YN'] = 0\n",
    "ViewLgItmDatDfSorted.loc[ViewLgItmDatDfSorted.item_price_bins == '[1250000, 1500000]', '_1250000_1500000_YN'] = 1\n",
    "ViewLgItmDatDfSorted['_1250000_1500000_count'] = pysqldf(\"SELECT SUM(_1250000_1500000_YN) over (PARTITION BY user_id order by server_time) from ViewLgItmDatDfSorted;\")\n",
    "del ViewLgItmDatDfSorted['_1250000_1500000_YN']\n",
    "gc.collect() \n",
    "print (\" ****** Executed ****** \")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making sure that dates are interpreted properly, before joining both the tables.\n",
    "format = '%Y-%m-%d %H:%M'\n",
    "ViewLgItmDatDfSorted['server_time'] = pd.to_datetime(ViewLgItmDatDfSorted['server_time'], format=format)\n",
    "format = '%Y-%m-%d %H:%M'\n",
    "trainAnalysisSorted['impression_time'] = pd.to_datetime(trainAnalysisSorted['impression_time'], format=format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ****** Executed ****** \n",
      " ****** Executed ****** \n",
      " ****** Executed ****** \n",
      " ****** Executed ****** \n",
      " ****** Executed ****** \n",
      " ****** Executed ****** \n",
      " ****** Executed ****** \n",
      " ****** Executed ****** \n",
      " ****** Executed ****** \n",
      " ****** Executed ****** \n",
      " ****** Executed ****** \n",
      " ****** Executed ****** \n",
      " ****** Executed ****** \n",
      " ****** Executed ****** \n",
      " ****** Executed ****** \n"
     ]
    }
   ],
   "source": [
    "trainAnalysisSorted['_0_500_count'] = pysqldf(\"select max(_0_500_count) from trainAnalysisSorted inner join ViewLgItmDatDfSorted where trainAnalysisSorted.user_id = ViewLgItmDatDfSorted.user_id and ((trainAnalysisSorted.impression_time > ViewLgItmDatDfSorted.server_time) or (trainAnalysisSorted.impression_time = ViewLgItmDatDfSorted.server_time)) group by trainAnalysisSorted.user_id,trainAnalysisSorted.impression_time;\")\n",
    "print (\" ****** Executed ****** \")\n",
    "trainAnalysisSorted['_500_1000_count'] = pysqldf(\"select max(_500_1000_count) from trainAnalysisSorted inner join ViewLgItmDatDfSorted where trainAnalysisSorted.user_id = ViewLgItmDatDfSorted.user_id and ((trainAnalysisSorted.impression_time > ViewLgItmDatDfSorted.server_time) or (trainAnalysisSorted.impression_time = ViewLgItmDatDfSorted.server_time)) group by trainAnalysisSorted.user_id,trainAnalysisSorted.impression_time;\")\n",
    "print (\" ****** Executed ****** \")\n",
    "trainAnalysisSorted['_1000_5000_count'] = pysqldf(\"select max(_1000_5000_count) from trainAnalysisSorted inner join ViewLgItmDatDfSorted where trainAnalysisSorted.user_id = ViewLgItmDatDfSorted.user_id and ((trainAnalysisSorted.impression_time > ViewLgItmDatDfSorted.server_time) or (trainAnalysisSorted.impression_time = ViewLgItmDatDfSorted.server_time)) group by trainAnalysisSorted.user_id,trainAnalysisSorted.impression_time;\")\n",
    "print (\" ****** Executed ****** \")\n",
    "trainAnalysisSorted['_5000_10000_count'] = pysqldf(\"select max(_5000_10000_count) from trainAnalysisSorted inner join ViewLgItmDatDfSorted where trainAnalysisSorted.user_id = ViewLgItmDatDfSorted.user_id and ((trainAnalysisSorted.impression_time > ViewLgItmDatDfSorted.server_time) or (trainAnalysisSorted.impression_time = ViewLgItmDatDfSorted.server_time)) group by trainAnalysisSorted.user_id,trainAnalysisSorted.impression_time;\")\n",
    "print (\" ****** Executed ****** \")\n",
    "trainAnalysisSorted['_10000_25000_count'] = pysqldf(\"select max(_10000_25000_count) from trainAnalysisSorted inner join ViewLgItmDatDfSorted where trainAnalysisSorted.user_id = ViewLgItmDatDfSorted.user_id and ((trainAnalysisSorted.impression_time > ViewLgItmDatDfSorted.server_time) or (trainAnalysisSorted.impression_time = ViewLgItmDatDfSorted.server_time)) group by trainAnalysisSorted.user_id,trainAnalysisSorted.impression_time;\")\n",
    "print (\" ****** Executed ****** \")\n",
    "trainAnalysisSorted['_25000_50000_count'] = pysqldf(\"select max(_25000_50000_count) from trainAnalysisSorted inner join ViewLgItmDatDfSorted where trainAnalysisSorted.user_id = ViewLgItmDatDfSorted.user_id and ((trainAnalysisSorted.impression_time > ViewLgItmDatDfSorted.server_time) or (trainAnalysisSorted.impression_time = ViewLgItmDatDfSorted.server_time)) group by trainAnalysisSorted.user_id,trainAnalysisSorted.impression_time;\")\n",
    "print (\" ****** Executed ****** \")\n",
    "trainAnalysisSorted['_50000_100000_count'] = pysqldf(\"select max(_50000_100000_count) from trainAnalysisSorted inner join ViewLgItmDatDfSorted where trainAnalysisSorted.user_id = ViewLgItmDatDfSorted.user_id and ((trainAnalysisSorted.impression_time > ViewLgItmDatDfSorted.server_time) or (trainAnalysisSorted.impression_time = ViewLgItmDatDfSorted.server_time)) group by trainAnalysisSorted.user_id,trainAnalysisSorted.impression_time;\")\n",
    "print (\" ****** Executed ****** \")\n",
    "trainAnalysisSorted['_100000_150000_count'] = pysqldf(\"select max(_100000_150000_count) from trainAnalysisSorted inner join ViewLgItmDatDfSorted where trainAnalysisSorted.user_id = ViewLgItmDatDfSorted.user_id and ((trainAnalysisSorted.impression_time > ViewLgItmDatDfSorted.server_time) or (trainAnalysisSorted.impression_time = ViewLgItmDatDfSorted.server_time)) group by trainAnalysisSorted.user_id,trainAnalysisSorted.impression_time;\")\n",
    "print (\" ****** Executed ****** \")\n",
    "trainAnalysisSorted['_150000_200000_count'] = pysqldf(\"select max(_150000_200000_count) from trainAnalysisSorted inner join ViewLgItmDatDfSorted where trainAnalysisSorted.user_id = ViewLgItmDatDfSorted.user_id and ((trainAnalysisSorted.impression_time > ViewLgItmDatDfSorted.server_time) or (trainAnalysisSorted.impression_time = ViewLgItmDatDfSorted.server_time)) group by trainAnalysisSorted.user_id,trainAnalysisSorted.impression_time;\")\n",
    "print (\" ****** Executed ****** \")\n",
    "trainAnalysisSorted['_200000_250000_count'] = pysqldf(\"select max(_200000_250000_count) from trainAnalysisSorted inner join ViewLgItmDatDfSorted where trainAnalysisSorted.user_id = ViewLgItmDatDfSorted.user_id and ((trainAnalysisSorted.impression_time > ViewLgItmDatDfSorted.server_time) or (trainAnalysisSorted.impression_time = ViewLgItmDatDfSorted.server_time)) group by trainAnalysisSorted.user_id,trainAnalysisSorted.impression_time;\")\n",
    "print (\" ****** Executed ****** \")\n",
    "trainAnalysisSorted['_250000_500000_count'] = pysqldf(\"select max(_250000_500000_count) from trainAnalysisSorted inner join ViewLgItmDatDfSorted where trainAnalysisSorted.user_id = ViewLgItmDatDfSorted.user_id and ((trainAnalysisSorted.impression_time > ViewLgItmDatDfSorted.server_time) or (trainAnalysisSorted.impression_time = ViewLgItmDatDfSorted.server_time)) group by trainAnalysisSorted.user_id,trainAnalysisSorted.impression_time;\")\n",
    "print (\" ****** Executed ****** \")\n",
    "trainAnalysisSorted['_500000_750000_count'] = pysqldf(\"select max(_500000_750000_count) from trainAnalysisSorted inner join ViewLgItmDatDfSorted where trainAnalysisSorted.user_id = ViewLgItmDatDfSorted.user_id and ((trainAnalysisSorted.impression_time > ViewLgItmDatDfSorted.server_time) or (trainAnalysisSorted.impression_time = ViewLgItmDatDfSorted.server_time)) group by trainAnalysisSorted.user_id,trainAnalysisSorted.impression_time;\")\n",
    "print (\" ****** Executed ****** \")\n",
    "trainAnalysisSorted['_750000_1000000_count'] = pysqldf(\"select max(_750000_1000000_count) from trainAnalysisSorted inner join ViewLgItmDatDfSorted where trainAnalysisSorted.user_id = ViewLgItmDatDfSorted.user_id and ((trainAnalysisSorted.impression_time > ViewLgItmDatDfSorted.server_time) or (trainAnalysisSorted.impression_time = ViewLgItmDatDfSorted.server_time)) group by trainAnalysisSorted.user_id,trainAnalysisSorted.impression_time;\")\n",
    "print (\" ****** Executed ****** \")\n",
    "trainAnalysisSorted['_1000000_1250000_count'] = pysqldf(\"select max(_1000000_1250000_count) from trainAnalysisSorted inner join ViewLgItmDatDfSorted where trainAnalysisSorted.user_id = ViewLgItmDatDfSorted.user_id and ((trainAnalysisSorted.impression_time > ViewLgItmDatDfSorted.server_time) or (trainAnalysisSorted.impression_time = ViewLgItmDatDfSorted.server_time)) group by trainAnalysisSorted.user_id,trainAnalysisSorted.impression_time;\")\n",
    "print (\" ****** Executed ****** \")\n",
    "trainAnalysisSorted['_1250000_1500000_count'] = pysqldf(\"select max(_1250000_1500000_count) from trainAnalysisSorted inner join ViewLgItmDatDfSorted where trainAnalysisSorted.user_id = ViewLgItmDatDfSorted.user_id and ((trainAnalysisSorted.impression_time > ViewLgItmDatDfSorted.server_time) or (trainAnalysisSorted.impression_time = ViewLgItmDatDfSorted.server_time)) group by trainAnalysisSorted.user_id,trainAnalysisSorted.impression_time;\")\n",
    "print (\" ****** Executed ****** \")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Determine the time of day, day of the week, day of month the impression was shown to the user.\n",
    "import datetime\n",
    "\n",
    "# The day of the week with Monday=0, Sunday=6.\n",
    "trainAnalysisSorted['day_of_week'] = pd.to_datetime(trainAnalysisSorted['impression_date'], format  = '%Y-%m-%d').dt.dayofweek\n",
    "\n",
    "trainAnalysisSorted['day_of_month'] = pd.to_datetime(trainAnalysisSorted['impression_date'], format = '%Y-%m-%d').dt.day\n",
    "\n",
    "trainAnalysisSorted['time_of_day'] = pd.to_datetime(trainAnalysisSorted['impression_timeStamp'], format = '%H:%M:%S').dt.hour\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
